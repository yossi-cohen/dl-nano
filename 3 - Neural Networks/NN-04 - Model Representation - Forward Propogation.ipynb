{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks - Model Representation - II - Forward Propogation\n",
    "Look at how to carry out the computation efficiently through a <font color=\"blue\">vectorized implementation</font>. \n",
    "<br>We'll also consider <font color=\"blue\">why NNs are good for learning complex non-linear things</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Original problem from before\n",
    "Sequence of steps to compute output of hypothesis are the equations below\n",
    "<img src=\"images/four nodes - activation example.png\">\n",
    "\n",
    "## Define some additional terms\n",
    "- $z_1^2 = Ɵ$<sub>10</sub>$^1x_0 + Ɵ$<sub>11</sub>$^1x_1 + Ɵ$<sub>12</sub>$^1x_2 + Ɵ$<sub>13</sub>$^1x_3$\n",
    "- Which means that $a_1^2 = g(z_1^2)$\n",
    "- N.B. Superscript numbers are the layer associated\n",
    "- Similarly, we define the others as $z_2^2$ and $z_3^2$\n",
    "  - These values are just a linear combination of the values\n",
    "\n",
    "\n",
    "## We can vectorize the neural network computation\n",
    "- define $x$ as the feature vector $x$\n",
    "- $z$<sup>(2)</sup> as the vector of $z$ values from the second layer\n",
    "<img src=\"images/vectorize-NN-1.png\">\n",
    "- $z$<sup>(2)</sup> is a [3x1] vector\n",
    "- We can vectorize the computation of the neural network as as follows in two steps\n",
    "  - $z$<sup>(2)</sup> $= Ɵ$<sup>(1)</sup>$x$\n",
    "    - $Ɵ$<sup>(1) is the matrix defined above\n",
    "    - $x$ is the feature vector\n",
    "  - $a$<sup>(2)</sup> $= g(z$<sup>(2)</sup>$)$\n",
    "    - $z$<sup>(2)</sup> is a [3x1] vecor\n",
    "    - $a$<sup>(2)</sup> is also a [3x1] vector\n",
    "    - $g()$ applies the *sigmoid* (logistic) function element wise to each member of the $z$<sup>(2)</sup> vector\n",
    "  - For notation completeness $a$<sup>(1)</sup> $= x$\n",
    "    - $a$<sup>(1)</sup> is the activations in the input layer\n",
    "    - Obviously the \"activation\" for the input layer is just the input!\n",
    "  - Having calculated then $z$<sup>(2)</sup> vector, we need to calculate $a_0^2$ \n",
    "    for the final hypothesis calculation\n",
    "    <img src=\"images/vectorize-NN-2.png\">\n",
    "\n",
    "- This process is also called **<font color=\"blue\">Forward Propagation</font>**\n",
    "  - Start off with activations of input unit (i.e. the $x$ vector as input)\n",
    "  - Forward propagate and calculate the activation of each layer sequentially\n",
    "  - This is a vectorized version of this implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural networks learning its own features\n",
    "Diagram below looks a lot like logistic regression\n",
    "- Layer 3 is a logistic regression node\n",
    "- The only difference is, instead of input a feature vector, \n",
    "  the features are just values calculated by the hidden layer\n",
    "- <font color=\"red\">The features $a_1^2$, $a_2^2$, and $a_3^2$ are \n",
    "  calculated/learned - not original features</font>\n",
    "- So instead of being constrained by the original input features, \n",
    "  a neural network can learn its own features to feed into logistic regression\n",
    "<img src=\"images/vectorize-NN-3.png\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network Architectures\n",
    "As well as the networks already seen, other architectures (topology) are possible\n",
    "- More/less nodes per layer\n",
    "- More layers\n",
    "  - By the time you get to the output layer you get very interesting non-linear hypothesis\n",
    "<img src=\"images/NN Architecture - multiple layers.png\">"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
