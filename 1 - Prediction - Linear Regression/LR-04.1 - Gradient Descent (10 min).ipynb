{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Minimizing the cost function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem\n",
    "We want to minimize $J(\\theta_0, \\theta_1)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Gradient Descent*\n",
    "- Applies to more general functions: $J(\\theta_0, \\theta_1, ..., \\theta_n)$\n",
    "- Used all over machine learning for *minimization*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How does it work?\n",
    "- Start with an initial guess: (0,0) or any other values\n",
    "- Keeping changing $\\theta_0, \\theta_1$ a little bit to try and reduce $J(\\theta_0, \\theta_1)$\n",
    "- Do so until you converge to a local minimum\n",
    "  - Has an interesting property (where you start can determine which minimum you end up)\n",
    "<img src=\"images/gradient-descent.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convex function\n",
    "- The linear regression cost function is always a convex function - always has a single minimum\n",
    "  - Bowl shaped\n",
    "  - One global optima\n",
    "  - So gradient descent will always converge to global optima\n",
    "<img src=\"images/J-3D.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A more formal definition\n",
    "- Do the following until covergence:\n",
    "<img src=\"images/gradient descent algorithm.png\">\n",
    "- What does this all mean?\n",
    "  - Update $\\theta_j$ by setting it to $(\\theta_j - \\alpha)$ times the partial derivative of the cost function \n",
    "    with respect to $\\theta_j$\n",
    "    - Do this <b><font color=\"#E30000\">simultaneously</font></b> for both $\\theta_0$ and $\\theta_1$\n",
    "  - $\\alpha$ is a number called the <b><font color=\"#1C3387\">learning rate</font></b> (controls how big a step to take)\n",
    "    - If $\\alpha$ is big we get an aggressive gradient descent *(may fail to converge)*\n",
    "    - If $\\alpha$ is small it takes tiny steps *(can take a long time to converge)*\n",
    "  - Derivative term: not going to talk about it now, derive it later..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
