{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"bordo\">Logistics Regression - Cost Function Derivative</font>\n",
    "<!-- source: http://feature-space.com/2011/10/28/logistic-cost-function-derivative/ -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the fun part, let's find the partial derivative of $J(\\theta)$\n",
    "<p>\n",
    "We start from the cost function definition:\n",
    "<p>\n",
    "<font size=\"4em\" color=\"gray\">\n",
    "(1) $J(\\theta) = -\\frac{1}{m}\\sum_{i=1}^m\\left[y^{(i)}log(h_{\\theta}(x^{(i)}) + (1-y^{(i)})log(1 - h_{\\theta}(x^{(i)})\\right]$\n",
    "</font>\n",
    "<p>\n",
    "Plug the definition for <font size=\"4em\" color=\"gray\">$h_{\\theta}(x^{(i)}) = \\frac{1}{1 + e^{-\\theta^Tx}}$</font> and partially derive by $\\theta_j$:\n",
    "<p>\n",
    "<font size=\"4em\" color=\"gray\">\n",
    "(2) $\\frac{\\partial}{\\partial\\theta_j} J(\\theta) = -\\frac{1}{m}\\sum_{i=1}^m \\frac{\\partial}{\\partial\\theta_j}\\left[y^{(i)}log\\left(\\frac{1}{1+e^{{-\\theta}^T{x}^{(i)}}}\\right) + (1-y^{(i)})log\\left(1-\\frac{1}{1+e^{{-\\theta}^T{x}^{(i)}}}\\right)\\right]$\n",
    "</font>\n",
    "<p>\n",
    "For brevity, let us note: &nbsp;&nbsp; \n",
    "<font size=\"3em\" color=\"gray\">\n",
    "$z = \\theta^Tx^{(i)} \\\\\n",
    "y = y^{(i)} \\\\ \n",
    "x = x^{(i)}$\n",
    "</font>\n",
    "<p>\n",
    "The part in brackets in (2) can now be written like so:\n",
    "<p>\n",
    "<font size=\"4em\" color=\"gray\">\n",
    "(3) $\\frac{\\partial}{\\partial\\theta_j} \\left[ y \\cdot log\\frac{1}{1+e^{-z}} + (1-y) \\cdot log \\left(1 - \\frac{1}{1 + e^{-z}}\\right) \\right]$\n",
    "</font>\n",
    "<p>\n",
    "Simplifying the right log:\n",
    "<p>\n",
    "<font size=\"4em\" color=\"gray\">\n",
    "(4) $\\frac{\\partial}{\\partial\\theta_j} \\left[ y \\cdot log\\frac{1}{1+e^{-z}} + (1-y) \\cdot log \\frac{e^{-z}}{1 + e^{-z}} \\right]$\n",
    "</font>\n",
    "<p>\n",
    "We know that: &nbsp; <font size=\"3em\" color=\"gray\"> $log(\\frac{a}{b}) = log(a) - log(b)$ </font> so we get:\n",
    "<p>\\frac{\\partial}{\\partial\\theta_j}\n",
    "<font size=\"4em\" color=\"gray\">\n",
    "(5) $\\frac{\\partial}{\\partial\\theta_j} \\left[ -y \\cdot log(1+e^{-z}) + (1-y) \\cdot \\left[ log(e^{-z}) - log(1 + e^{-z})\\right]\\right]$\n",
    "</font>\n",
    "<p>\n",
    "Simplyfying <font size=\"3em\" color=\"gray\">$log(e^{-z}) = -z$</font> and pulling out the minus sign, we get:\n",
    "<p>\n",
    "<font size=\"4em\" color=\"gray\">\n",
    "(6) $\\frac{\\partial}{\\partial\\theta_j}\\left[-y \\cdot log(1+e^{-z}) - (1-y) \\cdot \\left[ z + log(1 + e^{-z}) \\right]\\right]$\n",
    "</font>\n",
    "<p>\n",
    "<u>Begin Derivation</u>\n",
    "<p>\n",
    "We know from calculus that: &nbsp;\n",
    "<font size=\"4em\" color=\"gray\">\n",
    "$log'(a) = \\frac{1}{a} \\\\\n",
    "\\left(e^a\\right)' = e^a$\n",
    "</font>\n",
    "<p>\n",
    "And from the chain rule for derivatives: &nbsp;\n",
    "<font size=\"4em\" color=\"gray\">\n",
    "$\\frac{d}{da}\\left(f \\cdot g(a)\\right) = \\frac{df}{dg} \\cdot \\frac{dg}{da} = f'(g) \\cdot g'(a)$\n",
    "</font>\n",
    "<p>\n",
    "This gives us:\n",
    "<p>\n",
    "<font size=\"4em\" color=\"gray\">\n",
    "(7) $-y\\frac{1}{1+e^{-z}} \\cdot e^{-z} \\cdot (-1) \\cdot z' - (1-y) \\left[ z' + \\frac{1}{1+e^{-z}} \\cdot e^{-z} \\cdot z' \\cdot (-1) \\right]$\n",
    "</font>\n",
    "<p>11\n",
    "rearranging and pulling $z'$ out we get:\n",
    "<p>\n",
    "<font size=\"4em\" color=\"gray\">\n",
    "(8) $z' \\left[y\\frac{1}{1+e^{-z}} \\cdot e^{-z} - (1-y) \\left( 1 - \\frac{1}{1+e^{-z}} \\cdot e^{-z} \\right) \\right]$\n",
    "</font>\n",
    "<p>\n",
    "Opening the parenthesis on the right of the equation, we get:\n",
    "<p>\n",
    "<font size=\"4em\" color=\"gray\">\n",
    "(9) $z' \\left(y\\frac{1}{1+e^{-z}} \\cdot e^{-z} - 1 + \\frac{1}{1+e^{-z}} \\cdot e^{-z} + y - y\\frac{1}{1+e^{-z}} \\cdot e^{-z} \\right)$\n",
    "</font>\n",
    "<p>\n",
    "The left and the right terms cancel and we get:\n",
    "<p>\n",
    "<font size=\"4em\" color=\"gray\">\n",
    "(10) $z' \\left(- 1 + \\frac{1}{1+e^{-z}} \\cdot e^{-z} + y\\right)$\n",
    "</font>\n",
    "<p>\n",
    "Rearranging the left term within the parenthesis (common denominator), we get:\n",
    "<p>\n",
    "<font size=\"4em\" color=\"gray\">\n",
    "(11) $z' \\left(- \\frac{1}{1+e^{-z}} + y\\right)$\n",
    "</font>\n",
    "<p>\n",
    "Plugging back the definition for <font size=\"3em\" color=\"gray\">$h_\\theta(x) = \\frac{1}{1+e^{-z}}$</font> we get:\n",
    "<p>\n",
    "<font size=\"4em\" color=\"gray\">\n",
    "(12) $z' \\left(y - h_\\theta(x)\\right)$\n",
    "</font>\n",
    "<p>\n",
    "Finally putting back the sum and replacing <font size=\"3em\" color=\"gray\">$z' = \\frac{\\partial}{\\partial\\theta_j}\\theta^Tx^{(i)} = x_{j}^{(i)}$</font>, we get:\n",
    "<p>\n",
    "<font size=\"4em\" color=\"blue\">\n",
    "(13) $\\frac{\\partial}{\\partial\\theta_j} J(\\theta) = \\frac{1}{m}\\sum_{i=1}^m{\\left(h_\\theta(x^{(i)}) - y^{(i)}\\right) \\cdot x_{j}^{(i)}}$\n",
    "</font>back\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recap: same as Linear Regression!\n",
    "<img src=\"images/Gradient Descent - 2.png\">"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
